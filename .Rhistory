minCases = min_cases,
Trials = trials,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
Precision = precision,
F1_Score = f1_score
)
)
}
}
}
# Ordenar los resultados por la métrica deseada (ej., F1_Score o Accuracy)
mejores_resultados <- mejores_resultados[order(-mejores_resultados$Accuracy, -mejores_resultados$F1_Score), ]
# Mostrar las mejores combinaciones
print(mejores_resultados)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
plot(modelo_c50)
summary(modelo_c50)
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
print(matriz_confusion)
# Grid search de hiperparámetros con métricas adicionales
mejores_resultados <- NULL
valores_cf <- c(0.05, 0.1, 0.15, 0.25)
valores_minCases <- c(5, 10, 15)
valores_trials <- c(5, 10, 20)
set.seed(42)  # Define la semilla para reproducibilidad
for (cf in valores_cf) {
for (min_cases in valores_minCases) {
for (trials in valores_trials) {
# Volver a dividir los datos en cada iteración para consistencia
indices <- createDataPartition(diabetes_data$Outcome, p = 0.7, list = FALSE)
train_data <- diabetes_data[indices, ]
test_data <- diabetes_data[-indices, ]
# Entrenar el modelo
modelo <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = cf, minCases = min_cases),
trials = trials)
# Evaluar
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
# Calcular métricas adicionales
accuracy <- matriz_confusion$overall['Accuracy']
sensitivity <- matriz_confusion$byClass['Sensitivity']
specificity <- matriz_confusion$byClass['Specificity']
precision <- matriz_confusion$byClass['Pos Pred Value']
f1_score <- (2 * precision * sensitivity) / (precision + sensitivity)
# Guardar los resultados
mejores_resultados <- rbind(
mejores_resultados,
data.frame(
CF = cf,
minCases = min_cases,
Trials = trials,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
Precision = precision,
F1_Score = f1_score
)
)
}
}
}
# Ordenar los resultados por la métrica deseada (ej., F1_Score o Accuracy)
mejores_resultados <- mejores_resultados[order(-mejores_resultados$Accuracy, -mejores_resultados$F1_Score), ]
# Mostrar las mejores combinaciones
print(mejores_resultados)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
plot(modelo_c50)
summary(modelo_c50)
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
print(matriz_confusion)
#Importar librerías
library(C50)
library(ggplot2)
library(caret)
library(rpart.plot)
library(party)
library(reshape2)
library(dplyr)
library(scales)
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
setwd("~/Desktop/LabAnalisisDC")
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Refactorizar el Outcome
diabetes_data$Outcome <- as.factor(diabetes_data$Outcome)
# # Calcular el número y porcentaje de ceros en cada columna
valores_cero <- sapply(diabetes_data, function(col) sum(col == 0, na.rm = TRUE))
porcentaje_cero <- (valores_cero / nrow(diabetes_data)) * 100
# Crear un data frame para visualizar los resultados
analisis_ceros <- data.frame(Variable = names(diabetes_data),
ValoresCero = valores_cero,
PorcentajeCero = porcentaje_cero)
# Mostrar las variables con valores cero y sus porcentajes
print(analisis_ceros)
# IMPUTACIÓN
# Definir función para reemplazar ceros por la mediana
reemplazar_con_mediana <- function(data, columnas) {
for (col in columnas) {
# Calcular la mediana excluyendo ceros
mediana <- median(data[[col]][data[[col]] != 0], na.rm = TRUE)
# Reemplazar ceros con la mediana
data[[col]][data[[col]] == 0] <- mediana
}
return(data)
}
# Especificar las columnas a procesar
columnas_a_procesar <- c("Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI")
# Aplicar la función al dataset
diabetes_data <- reemplazar_con_mediana(diabetes_data, columnas_a_procesar)
# Verificar resultados
summary(diabetes_data)
# Análisis exploratorio
ggplot(diabetes_data, aes(x = Glucose)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Glucosa", x = "Glucosa", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Pregnancies)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Embarazos", x = "Embarazos", y = "Frecuencia")
ggplot(diabetes_data, aes(x = BloodPressure)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Presión Arterial", x = "Presión Arterial", y = "Frecuencia")
ggplot(diabetes_data, aes(x = SkinThickness)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Grosor de Piel", x = "Grosor de Piel", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Insulin)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Insulina", x = "Insulina", y = "Frecuencia")
ggplot(diabetes_data, aes(x = BMI)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de IMC", x = "IMC", y = "Frecuencia")
ggplot(diabetes_data, aes(x = DiabetesPedigreeFunction)) +
geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Distribución de la Función de Pedigrí de Diabetes", x = "Diabetes Pedigree Function", y = "Frecuencia") +
theme_minimal()
ggplot(diabetes_data, aes(x = Age)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Edad", x = "Edad", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Outcome)) +
geom_bar(fill = "salmon", color = "black") +
labs(title = "Distribución de Outcome", x = "Resultado de Diabetes", y = "Frecuencia")
# Estadísticas descriptivas de las variables
summary(diabetes_data)
# Selección de columnas numéricas
variables_numericas <- diabetes_data[sapply(diabetes_data, is.numeric)]
# Calcular la matriz de correlación
matriz_correlacion <- cor(variables_numericas, use = "complete.obs")
# Ver la matriz de correlación
print(matriz_correlacion)
# Graficar matriz de correlacion
correlacion_larga <- melt(matriz_correlacion)
ggplot(data = correlacion_larga, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1, 1), name = "Correlación") +
theme_minimal() +
labs(title = "Matriz de Correlación", x = "", y = "") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Dividir los datos en conjunto de entrenamiento y prueba
set.seed(42) # Para reproducibilidad
indices <- createDataPartition(diabetes_data$Outcome, p = 0.7, list = FALSE)
train_data <- diabetes_data[indices, ] # EXPLICAR POR QUÉ SE ESCOGIÓ EL 70% DE LOS DATOS PARA EL ENTRENAMIENTO
test_data <- diabetes_data[-indices, ]
# Falsos positivos y negativos
false_positive <- which(predicciones == 1 & test_data$Outcome == 0)
false_negative <- which(predicciones == 0 & test_data$Outcome == 1)
# Mostrar los ejemplos mal clasificados
print(test_data[false_positive, ])
print(test_data[false_negative, ])
# Proporción de clases en el conjunto de entrenamiento y prueba
table(train_data$Outcome)
table(test_data$Outcome)
# Grid search de hiperparámetros con métricas adicionales
mejores_resultados <- NULL
valores_cf <- c(0.05, 0.1, 0.15, 0.25)
valores_minCases <- c(5, 10, 15)
valores_trials <- c(5, 10, 20)
set.seed(42)  # Define la semilla para reproducibilidad
for (cf in valores_cf) {
for (min_cases in valores_minCases) {
for (trials in valores_trials) {
# Volver a dividir los datos en cada iteración para consistencia
indices <- createDataPartition(diabetes_data$Outcome, p = 0.7, list = FALSE)
train_data <- diabetes_data[indices, ]
test_data <- diabetes_data[-indices, ]
# Entrenar el modelo
modelo <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = cf, minCases = min_cases),
trials = trials)
# Evaluar
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
# Calcular métricas adicionales
accuracy <- matriz_confusion$overall['Accuracy']
sensitivity <- matriz_confusion$byClass['Sensitivity']
specificity <- matriz_confusion$byClass['Specificity']
precision <- matriz_confusion$byClass['Pos Pred Value']
f1_score <- (2 * precision * sensitivity) / (precision + sensitivity)
# Guardar los resultados
mejores_resultados <- rbind(
mejores_resultados,
data.frame(
CF = cf,
minCases = min_cases,
Trials = trials,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
Precision = precision,
F1_Score = f1_score
)
)
}
}
}
# Ordenar los resultados por la métrica deseada (ej., F1_Score o Accuracy)
mejores_resultados <- mejores_resultados[order(-mejores_resultados$Accuracy, -mejores_resultados$F1_Score), ]
# Mostrar las mejores combinaciones
print(mejores_resultados)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
plot(modelo_c50)
summary(modelo_c50)
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
print(matriz_confusion)
#Importar librerías
library(C50)
library(ggplot2)
library(caret)
library(rpart.plot)
library(party)
library(reshape2)
library(dplyr)
library(scales)
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
setwd("~/Desktop/LabAnalisisDC")
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Refactorizar el Outcome
diabetes_data$Outcome <- as.factor(diabetes_data$Outcome)
# # Calcular el número y porcentaje de ceros en cada columna
valores_cero <- sapply(diabetes_data, function(col) sum(col == 0, na.rm = TRUE))
porcentaje_cero <- (valores_cero / nrow(diabetes_data)) * 100
# Crear un data frame para visualizar los resultados
analisis_ceros <- data.frame(Variable = names(diabetes_data),
ValoresCero = valores_cero,
PorcentajeCero = porcentaje_cero)
# Mostrar las variables con valores cero y sus porcentajes
print(analisis_ceros)
# IMPUTACIÓN
# Definir función para reemplazar ceros por la mediana
reemplazar_con_mediana <- function(data, columnas) {
for (col in columnas) {
# Calcular la mediana excluyendo ceros
mediana <- median(data[[col]][data[[col]] != 0], na.rm = TRUE)
# Reemplazar ceros con la mediana
data[[col]][data[[col]] == 0] <- mediana
}
return(data)
}
# Especificar las columnas a procesar
columnas_a_procesar <- c("Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI")
# Aplicar la función al dataset
diabetes_data <- reemplazar_con_mediana(diabetes_data, columnas_a_procesar)
# Verificar resultados
summary(diabetes_data)
# Análisis exploratorio
ggplot(diabetes_data, aes(x = Glucose)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Glucosa", x = "Glucosa", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Pregnancies)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Embarazos", x = "Embarazos", y = "Frecuencia")
ggplot(diabetes_data, aes(x = BloodPressure)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Presión Arterial", x = "Presión Arterial", y = "Frecuencia")
ggplot(diabetes_data, aes(x = SkinThickness)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Grosor de Piel", x = "Grosor de Piel", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Insulin)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Insulina", x = "Insulina", y = "Frecuencia")
ggplot(diabetes_data, aes(x = BMI)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de IMC", x = "IMC", y = "Frecuencia")
ggplot(diabetes_data, aes(x = DiabetesPedigreeFunction)) +
geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Distribución de la Función de Pedigrí de Diabetes", x = "Diabetes Pedigree Function", y = "Frecuencia") +
theme_minimal()
ggplot(diabetes_data, aes(x = Age)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Edad", x = "Edad", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Outcome)) +
geom_bar(fill = "salmon", color = "black") +
labs(title = "Distribución de Outcome", x = "Resultado de Diabetes", y = "Frecuencia")
# Estadísticas descriptivas de las variables
summary(diabetes_data)
# Selección de columnas numéricas
variables_numericas <- diabetes_data[sapply(diabetes_data, is.numeric)]
# Calcular la matriz de correlación
matriz_correlacion <- cor(variables_numericas, use = "complete.obs")
# Ver la matriz de correlación
print(matriz_correlacion)
# Graficar matriz de correlacion
correlacion_larga <- melt(matriz_correlacion)
ggplot(data = correlacion_larga, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1, 1), name = "Correlación") +
theme_minimal() +
labs(title = "Matriz de Correlación", x = "", y = "") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Dividir los datos en conjunto de entrenamiento y prueba
set.seed(42) # Para reproducibilidad
indices <- createDataPartition(diabetes_data$Outcome, p = 0.7, list = FALSE)
train_data <- diabetes_data[indices, ] # EXPLICAR POR QUÉ SE ESCOGIÓ EL 70% DE LOS DATOS PARA EL ENTRENAMIENTO
test_data <- diabetes_data[-indices, ]
# Falsos positivos y negativos
false_positive <- which(predicciones == 1 & test_data$Outcome == 0)
false_negative <- which(predicciones == 0 & test_data$Outcome == 1)
# Mostrar los ejemplos mal clasificados
print(test_data[false_positive, ])
print(test_data[false_negative, ])
# Proporción de clases en el conjunto de entrenamiento y prueba
table(train_data$Outcome)
table(test_data$Outcome)
# Grid search de hiperparámetros con métricas adicionales
mejores_resultados <- NULL
valores_cf <- c(0.05, 0.1, 0.15, 0.25)
valores_minCases <- c(5, 10, 15)
valores_trials <- c(5, 10, 20)
set.seed(42)  # Define la semilla para reproducibilidad
for (cf in valores_cf) {
for (min_cases in valores_minCases) {
for (trials in valores_trials) {
# Volver a dividir los datos en cada iteración para consistencia
indices <- createDataPartition(diabetes_data$Outcome, p = 0.7, list = FALSE)
train_data <- diabetes_data[indices, ]
test_data <- diabetes_data[-indices, ]
# Entrenar el modelo
modelo <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = cf, minCases = min_cases),
trials = trials)
# Evaluar
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
# Calcular métricas adicionales
accuracy <- matriz_confusion$overall['Accuracy']
sensitivity <- matriz_confusion$byClass['Sensitivity']
specificity <- matriz_confusion$byClass['Specificity']
precision <- matriz_confusion$byClass['Pos Pred Value']
f1_score <- (2 * precision * sensitivity) / (precision + sensitivity)
# Guardar los resultados
mejores_resultados <- rbind(
mejores_resultados,
data.frame(
CF = cf,
minCases = min_cases,
Trials = trials,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
Precision = precision,
F1_Score = f1_score
)
)
}
}
}
# Ordenar los resultados por la métrica deseada (ej., F1_Score o Accuracy)
mejores_resultados <- mejores_resultados[order(-mejores_resultados$Accuracy, -mejores_resultados$F1_Score), ]
# Mostrar las mejores combinaciones
print(mejores_resultados)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
plot(modelo_c50)
summary(modelo_c50)
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
print(matriz_confusion)
# Grid search de hiperparámetros con métricas adicionales
mejores_resultados <- NULL
valores_cf <- c(0.05, 0.1, 0.15, 0.25)
valores_minCases <- c(5, 10, 15)
valores_trials <- c(5, 10, 20)
for (cf in valores_cf) {
for (min_cases in valores_minCases) {
for (trials in valores_trials) {
# Entrenar el modelo con la combinación actual
modelo <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = cf, minCases = min_cases),
trials = trials)
# Evaluar en el conjunto de prueba
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
# Calcular métricas adicionales
accuracy <- matriz_confusion$overall['Accuracy']
sensitivity <- matriz_confusion$byClass['Sensitivity']
specificity <- matriz_confusion$byClass['Specificity']
precision <- matriz_confusion$byClass['Pos Pred Value']
f1_score <- (2 * precision * sensitivity) / (precision + sensitivity)
# Guardar los resultados
mejores_resultados <- rbind(
mejores_resultados,
data.frame(
CF = cf,
minCases = min_cases,
Trials = trials,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
Precision = precision,
F1_Score = f1_score
)
)
}
}
}
# Ordenar los resultados por la métrica deseada (ej., F1_Score o Accuracy)
mejores_resultados <- mejores_resultados[order(-mejores_resultados$Accuracy, -mejores_resultados$F1_Score), ]
# Mostrar las mejores combinaciones
print(mejores_resultados)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
plot(modelo_c50)
summary(modelo_c50)
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
print(matriz_confusion)
# Grid search de hiperparámetros con métricas adicionales
mejores_resultados <- NULL
valores_cf <- c(0.05, 0.1, 0.15, 0.25)
valores_minCases <- c(5, 10, 15)
valores_trials <- c(5, 10, 20)
for (cf in valores_cf) {
for (min_cases in valores_minCases) {
for (trials in valores_trials) {
# Entrenar el modelo con la combinación actual
modelo <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = cf, minCases = min_cases),
trials = trials)
# Evaluar en el conjunto de prueba
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
# Calcular métricas adicionales
accuracy <- matriz_confusion$overall['Accuracy']
sensitivity <- matriz_confusion$byClass['Sensitivity']
specificity <- matriz_confusion$byClass['Specificity']
precision <- matriz_confusion$byClass['Pos Pred Value']
f1_score <- (2 * precision * sensitivity) / (precision + sensitivity)
# Guardar los resultados
mejores_resultados <- rbind(
mejores_resultados,
data.frame(
CF = cf,
minCases = min_cases,
Trials = trials,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
Precision = precision,
F1_Score = f1_score
)
)
}
}
}
# Ordenar los resultados por la métrica deseada (ej., F1_Score o Accuracy)
mejores_resultados <- mejores_resultados[order(-mejores_resultados$Accuracy, -mejores_resultados$F1_Score), ]
# Mostrar las mejores combinaciones
print(mejores_resultados)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
plot(modelo_c50)
summary(modelo_c50)
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
print(matriz_confusion)
source("~/Desktop/LabAnalisisDC/lab4.R")
