# Calcular la nueva sensibilidad y especificidad
VP_optimo <- matriz_confusion_optimo[2, 2]  # Verdaderos positivos
VN_optimo <- matriz_confusion_optimo[1, 1]  # Verdaderos negativos
FP_optimo <- matriz_confusion_optimo[2, 1]  # Falsos positivos
FN_optimo <- matriz_confusion_optimo[1, 2]  # Falsos negativos
# Sensibilidad
sensibilidad_optima <- VP_optimo / (VP_optimo + FN_optimo)
cat("Nueva Sensibilidad:", round(sensibilidad_optima, 4), "\n")
# Especificidad
especificidad_optima <- VN_optimo / (VN_optimo + FP_optimo)
cat("Nueva Especificidad:", round(especificidad_optima, 4), "\n")
# Calcular la precisión del modelo con el nuevo umbral
precision_optima <- mean(predicciones_binarias_optimo == diabetes_data$Outcome)
cat("Nueva Precisión del modelo:", round(precision_optima, 4), "\n")
# Configurar los parámetros de validación cruzada
control <- trainControl(method = "cv", number = 10)  # 10 pliegues
# Ajustar el modelo reducido (3 variables: Glucose, BMI, DiabetesPedigreeFunction)
modelo_logistico_reducido <- train(Outcome ~ Glucose + BMI + DiabetesPedigreeFunction,
data = diabetes_data,
method = "glm",
family = binomial,
trControl = control)
# Matriz de confusión con el nuevo umbral
matriz_confusion_optimo <- table(Predicho = predicciones_binarias_optimo, Real = diabetes_data$Outcome)
# Calcular las probabilidades de predicción para la curva ROC
roc_obj_optimo <- roc(diabetes_data$Outcome, prob_predicciones)
# Graficar la curva ROC para el modelo completo con el nuevo umbral
plot(roc_obj_optimo, main = "Curva ROC - Modelo Completo (Umbral Óptimo 0.3401)", col = "blue", lwd = 2)
auc_optimo <- auc(roc_obj_optimo)
cat("Área bajo la curva (AUC) con el umbral óptimo:", auc_optimo, "\n")
# Matriz de confusión con el nuevo umbral
matriz_confusion_optimo <- table(Predicho = predicciones_binarias_optimo, Real = diabetes_data$Outcome)
# Calcular las probabilidades de predicción para la curva ROC
roc_obj_optimo <- roc(diabetes_data$Outcome, prob_predicciones)
# Graficar la curva ROC para el modelo completo con el nuevo umbral
plot(roc_obj_optimo, main = "Curva ROC - Modelo Completo (Umbral Óptimo 0.3401)", col = "blue", lwd = 2)
auc_optimo <- auc(roc_obj_optimo)
cat("Área bajo la curva (AUC) con el umbral óptimo:", auc_optimo, "\n")
# Mostrar la nueva matriz de confusión
print(matriz_confusion_optimo)
# Graficar la matriz de confusión
pheatmap(as.matrix(matriz_confusion_optimo), display_numbers = TRUE, color = colorRampPalette(c("bisque", "aquamarine"))(50),
fontsize_number = 14, legend = TRUE, main = "Matriz de Confusión", cluster_rows = FALSE, cluster_cols = FALSE)
# Calcular la nueva sensibilidad y especificidad
VP_optimo <- matriz_confusion_optimo[2, 2]  # Verdaderos positivos
VN_optimo <- matriz_confusion_optimo[1, 1]  # Verdaderos negativos
FP_optimo <- matriz_confusion_optimo[2, 1]  # Falsos positivos
FN_optimo <- matriz_confusion_optimo[1, 2]  # Falsos negativos
# Sensibilidad
sensibilidad_optima <- VP_optimo / (VP_optimo + FN_optimo)
cat("Nueva Sensibilidad:", round(sensibilidad_optima, 4), "\n")
# Especificidad
especificidad_optima <- VN_optimo / (VN_optimo + FP_optimo)
cat("Nueva Especificidad:", round(especificidad_optima, 4), "\n")
# Calcular la precisión del modelo con el nuevo umbral
precision_optima <- mean(predicciones_binarias_optimo == diabetes_data$Outcome)
cat("Nueva Precisión del modelo:", round(precision_optima, 4), "\n")
# Configurar los parámetros de validación cruzada
control <- trainControl(method = "cv", number = 10)  # 10 pliegues
# Ajustar el modelo reducido (3 variables: Glucose, BMI, DiabetesPedigreeFunction)
modelo_logistico_reducido <- train(Outcome ~ Glucose + BMI + DiabetesPedigreeFunction,
data = diabetes_data,
method = "glm",
family = binomial,
trControl = control)
# Graficar residuals vs fitted values para el modelo original (opcional)
plot(fitted(modelo_logistico), residuals(modelo_logistico, type = "deviance"),
main = "Residuals vs Fitted",
xlab = "Valores ajustados",
ylab = "Residuos deviance")
abline(h = 0, col = "red", lwd = 2)
### ---------------------------------------------
# Predecir probabilidades para el modelo reducido (probabilidad de clase 1)
prob_predicciones_reducido <- predict(modelo_logistico_reducido, type = "prob")[,2]  # Extraer la probabilidad de la clase 1
# Aplicar el umbral óptimo también al modelo reducido
predicciones_binarias_reducido <- ifelse(prob_predicciones_reducido > nuevo_umbral, 1, 0)
# Matriz de confusión para el modelo reducido
matriz_confusion_reducido <- table(Predicho = predicciones_binarias_reducido, Real = diabetes_data$Outcome)
print(matriz_confusion_reducido)
# Crear un gráfico de barras para la matriz de confusión del modelo reducido
confusion_data_reducido <- as.data.frame(as.table(matriz_confusion_reducido))
ggplot(confusion_data_reducido, aes(x = Real, y = Freq, fill = Predicho)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Matriz de Confusión - Modelo Reducido", x = "Valor Real", y = "Frecuencia")
# Generar la curva ROC para el modelo reducido
roc_obj_reducido <- roc(diabetes_data$Outcome, prob_predicciones_reducido)
# Graficar la curva ROC para el modelo reducido
plot(roc_obj_reducido, main = "Curva ROC - Modelo Reducido (Umbral Óptimo 0.285)", col = "red", lwd = 2)
auc_reducido <- auc(roc_obj_reducido)
cat("Área bajo la curva (AUC) para el modelo reducido:", auc_reducido, "\n")
# Graficar ambas curvas ROC en el mismo gráfico para comparar
plot(roc_obj_optimo, main = "Curvas ROC - Comparación Modelo Completo vs. Reducido", col = "blue", lwd = 2)
lines(roc_obj_reducido, col = "red", lwd = 2)
# Asegurarse de que Outcome es un factor
diabetes_data$Outcome <- factor(diabetes_data$Outcome)
# Ajustar el modelo de regresión logística
modelo_logistico <- glm(Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age,
data = diabetes_data,
family = binomial)
# Resumen del modelo
summary(modelo_logistico)
# Graficar pair plot
ggpairs(diabetes_data, aes(color = Outcome))
# Obtener los coeficientes del modelo de regresión logística
coeficientes <- as.data.frame(coef(modelo_logistico))
# Renombrar la columna con los coeficientes
colnames(coeficientes) <- "Coeficiente"
# Crear una columna con los nombres de las variables
coeficientes$Variable <- rownames(coeficientes)
# Eliminar la fila del intercepto, si no deseas incluirla
coeficientes <- coeficientes[-1, ]
# Graficar los coeficientes
ggplot(coeficientes, aes(x = reorder(Variable, abs(Coeficiente)), y = Coeficiente)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Importancia de las variables en el modelo logístico",
x = "Variables", y = "Coeficientes del modelo")
# Predecir probabilidades de tener diabetes (Outcome = 1)
prob_predicciones <- predict(modelo_logistico, type = "response")
# Convertir probabilidades a predicciones binarias (0 o 1)
predicciones_binarias <- ifelse(prob_predicciones > 0.35, 1, 0)
# Matriz de confusión
matriz_confusion <- table(Predicho = predicciones_binarias, Real = diabetes_data$Outcome)
# Graficar la matriz de confusión
pheatmap(as.matrix(matriz_confusion), display_numbers = TRUE, color = colorRampPalette(c("bisque", "aquamarine"))(50),
fontsize_number = 14, legend = TRUE, main = "Matriz de Confusión", cluster_rows = FALSE, cluster_cols = FALSE)
# Calcular sensibilidad y especificidad
VP <- matriz_confusion[2, 2]  # Verdaderos positivos (Outcome = 1 y predicho = 1)
VN <- matriz_confusion[1, 1]  # Verdaderos negativos (Outcome = 0 y predicho = 0)
FP <- matriz_confusion[2, 1]  # Falsos positivos (Outcome = 0 pero predicho = 1)
FN <- matriz_confusion[1, 2]  # Falsos negativos (Outcome = 1 pero predicho = 0)
# Sensibilidad
sensibilidad <- VP / (VP + FN)
cat("Sensibilidad:", round(sensibilidad, 4), "\n")
# Especificidad
especificidad <- VN / (VN + FP)
cat("Especificidad:", round(especificidad, 4), "\n")
# Calcular la precisión del modelo
precision <- mean(predicciones_binarias == diabetes_data$Outcome)
print(paste("Precisión del modelo:", round(precision, 4)))
# Calcular la curva ROC y AUC
roc_obj <- roc(diabetes_data$Outcome, prob_predicciones)
plot(roc_obj)
auc(roc_obj)
# Encontrar el mejor umbral según la curva ROC
coords(roc_obj, "best", ret = "threshold")
# Crear un gráfico de barras para la matriz de confusión del modelo completo
confusion_data <- as.data.frame(as.table(matriz_confusion))
ggplot(confusion_data, aes(x = Real, y = Freq, fill = Predicho)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Matriz de Confusión - Modelo Completo", x = "Valor Real", y = "Frecuencia")
# Aplicar el nuevo umbral óptimo
nuevo_umbral <- 0.3401293
# Convertir probabilidades a predicciones binarias usando el nuevo umbral
predicciones_binarias_optimo <- ifelse(prob_predicciones > nuevo_umbral, 1, 0)
# Matriz de confusión con el nuevo umbral
matriz_confusion_optimo <- table(Predicho = predicciones_binarias_optimo, Real = diabetes_data$Outcome)
# Calcular las probabilidades de predicción para la curva ROC
roc_obj_optimo <- roc(diabetes_data$Outcome, prob_predicciones)
# Graficar la curva ROC para el modelo completo con el nuevo umbral
plot(roc_obj_optimo, main = "Curva ROC - Modelo Completo (Umbral Óptimo 0.3401)", col = "blue", lwd = 2)
auc_optimo <- auc(roc_obj_optimo)
cat("Área bajo la curva (AUC) con el umbral óptimo:", auc_optimo, "\n")
# Mostrar la nueva matriz de confusión
print(matriz_confusion_optimo)
# Graficar la matriz de confusión
pheatmap(as.matrix(matriz_confusion_optimo), display_numbers = TRUE, color = colorRampPalette(c("bisque", "aquamarine"))(50),
fontsize_number = 14, legend = TRUE, main = "Matriz de Confusión", cluster_rows = FALSE, cluster_cols = FALSE)
# Calcular la nueva sensibilidad y especificidad
VP_optimo <- matriz_confusion_optimo[2, 2]  # Verdaderos positivos
VN_optimo <- matriz_confusion_optimo[1, 1]  # Verdaderos negativos
FP_optimo <- matriz_confusion_optimo[2, 1]  # Falsos positivos
FN_optimo <- matriz_confusion_optimo[1, 2]  # Falsos negativos
# Sensibilidad
sensibilidad_optima <- VP_optimo / (VP_optimo + FN_optimo)
cat("Nueva Sensibilidad:", round(sensibilidad_optima, 4), "\n")
# Especificidad
especificidad_optima <- VN_optimo / (VN_optimo + FP_optimo)
cat("Nueva Especificidad:", round(especificidad_optima, 4), "\n")
# Calcular la precisión del modelo con el nuevo umbral
precision_optima <- mean(predicciones_binarias_optimo == diabetes_data$Outcome)
cat("Nueva Precisión del modelo:", round(precision_optima, 4), "\n")
# Configurar los parámetros de validación cruzada
control <- trainControl(method = "cv", number = 10)  # 10 pliegues
# Ajustar el modelo reducido (3 variables: Glucose, BMI, DiabetesPedigreeFunction)
modelo_logistico_reducido <- train(Outcome ~ Glucose + BMI + DiabetesPedigreeFunction,
data = diabetes_data,
method = "glm",
family = binomial,
trControl = control)
# Graficar residuals vs fitted values para el modelo original (opcional)
plot(fitted(modelo_logistico), residuals(modelo_logistico, type = "deviance"),
main = "Residuals vs Fitted",
xlab = "Valores ajustados",
ylab = "Residuos deviance")
abline(h = 0, col = "red", lwd = 2)
### ---------------------------------------------
# Predecir probabilidades para el modelo reducido (probabilidad de clase 1)
prob_predicciones_reducido <- predict(modelo_logistico_reducido, type = "prob")[,2]  # Extraer la probabilidad de la clase 1
# Aplicar el umbral óptimo también al modelo reducido
predicciones_binarias_reducido <- ifelse(prob_predicciones_reducido > nuevo_umbral, 1, 0)
# Matriz de confusión para el modelo reducido
matriz_confusion_reducido <- table(Predicho = predicciones_binarias_reducido, Real = diabetes_data$Outcome)
print(matriz_confusion_reducido)
# Crear un gráfico de barras para la matriz de confusión del modelo reducido
confusion_data_reducido <- as.data.frame(as.table(matriz_confusion_reducido))
ggplot(confusion_data_reducido, aes(x = Real, y = Freq, fill = Predicho)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Matriz de Confusión - Modelo Reducido", x = "Valor Real", y = "Frecuencia")
# Generar la curva ROC para el modelo reducido
roc_obj_reducido <- roc(diabetes_data$Outcome, prob_predicciones_reducido)
# Graficar la curva ROC para el modelo reducido
plot(roc_obj_reducido, main = "Curva ROC - Modelo Reducido (Umbral Óptimo 0.285)", col = "red", lwd = 2)
# Crear un gráfico de barras para la matriz de confusión del modelo reducido
confusion_data_reducido <- as.data.frame(as.table(matriz_confusion_reducido))
ggplot(confusion_data_reducido, aes(x = Real, y = Freq, fill = Predicho)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Matriz de Confusión - Modelo Reducido", x = "Valor Real", y = "Frecuencia")
# Generar la curva ROC para el modelo reducido
roc_obj_reducido <- roc(diabetes_data$Outcome, prob_predicciones_reducido)
# Graficar la curva ROC para el modelo reducido
plot(roc_obj_reducido, main = "Curva ROC - Modelo Reducido (Umbral Óptimo 0.285)", col = "red", lwd = 2)
auc_reducido <- auc(roc_obj_reducido)
cat("Área bajo la curva (AUC) para el modelo reducido:", auc_reducido, "\n")
# Graficar ambas curvas ROC en el mismo gráfico para comparar
plot(roc_obj_optimo, main = "Curvas ROC - Comparación Modelo Completo vs. Reducido", col = "blue", lwd = 2)
lines(roc_obj_reducido, col = "red", lwd = 2)
legend("bottomright", legend = c("Modelo Completo", "Modelo Reducido"), col = c("blue", "red"), lwd = 2)
# Graficar los coeficientes
ggplot(coeficientes, aes(x = reorder(Variable, abs(Coeficiente)), y = Coeficiente)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Importancia de las variables en el modelo logístico",
x = "Variables", y = "Coeficientes del modelo")
# Predecir probabilidades de tener diabetes (Outcome = 1)
prob_predicciones <- predict(modelo_logistico, type = "response")
# Convertir probabilidades a predicciones binarias (0 o 1)
predicciones_binarias <- ifelse(prob_predicciones > 0.35, 1, 0)
# Matriz de confusión
matriz_confusion <- table(Predicho = predicciones_binarias, Real = diabetes_data$Outcome)
# Graficar la matriz de confusión
pheatmap(as.matrix(matriz_confusion), display_numbers = TRUE, color = colorRampPalette(c("bisque", "aquamarine"))(50),
fontsize_number = 14, legend = TRUE, main = "Matriz de Confusión", cluster_rows = FALSE, cluster_cols = FALSE)
# Calcular sensibilidad y especificidad
VP <- matriz_confusion[2, 2]  # Verdaderos positivos (Outcome = 1 y predicho = 1)
VN <- matriz_confusion[1, 1]  # Verdaderos negativos (Outcome = 0 y predicho = 0)
FP <- matriz_confusion[2, 1]  # Falsos positivos (Outcome = 0 pero predicho = 1)
FN <- matriz_confusion[1, 2]  # Falsos negativos (Outcome = 1 pero predicho = 0)
# Sensibilidad
sensibilidad <- VP / (VP + FN)
cat("Sensibilidad:", round(sensibilidad, 4), "\n")
# Especificidad
especificidad <- VN / (VN + FP)
cat("Especificidad:", round(especificidad, 4), "\n")
# Calcular la precisión del modelo
precision <- mean(predicciones_binarias == diabetes_data$Outcome)
print(paste("Precisión del modelo:", round(precision, 4)))
# Calcular la curva ROC y AUC
roc_obj <- roc(diabetes_data$Outcome, prob_predicciones)
plot(roc_obj)
auc(roc_obj)
# Encontrar el mejor umbral según la curva ROC
coords(roc_obj, "best", ret = "threshold")
# Crear un gráfico de barras para la matriz de confusión del modelo completo
confusion_data <- as.data.frame(as.table(matriz_confusion))
ggplot(confusion_data, aes(x = Real, y = Freq, fill = Predicho)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Matriz de Confusión - Modelo Completo", x = "Valor Real", y = "Frecuencia")
# Graficar la matriz de confusión
pheatmap(as.matrix(matriz_confusion), display_numbers = TRUE, color = colorRampPalette(c("bisque", "aquamarine"))(50),
fontsize_number = 14, legend = TRUE, main = "Matriz de Confusión", cluster_rows = FALSE, cluster_cols = FALSE)
# Graficar la matriz de confusión
pheatmap(as.matrix(matriz_confusion), display_numbers = TRUE, color = colorRampPalette(c("bisque", "aquamarine"))(50),
fontsize_number = 14, legend = TRUE, main = "Matriz de Confusión", cluster_rows = FALSE, cluster_cols = FALSE)
#Importar librerías
library(C50)
library(ggplot2)
library(caret)
library(rpart.plot)
library(party)
library(reshape2)
library(dplyr)
library(scales)
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
setwd("~/Desktop/LabAnalisisDC")
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Refactorizar el Outcome
diabetes_data$Outcome <- as.factor(diabetes_data$Outcome)
# # Calcular el número y porcentaje de ceros en cada columna
valores_cero <- sapply(diabetes_data, function(col) sum(col == 0, na.rm = TRUE))
porcentaje_cero <- (valores_cero / nrow(diabetes_data)) * 100
# Crear un data frame para visualizar los resultados
analisis_ceros <- data.frame(Variable = names(diabetes_data),
ValoresCero = valores_cero,
PorcentajeCero = porcentaje_cero)
# Mostrar las variables con valores cero y sus porcentajes
print(analisis_ceros)
# IMPUTACIÓN
# Definir función para reemplazar ceros por la mediana
reemplazar_con_mediana <- function(data, columnas) {
for (col in columnas) {
# Calcular la mediana excluyendo ceros
mediana <- median(data[[col]][data[[col]] != 0], na.rm = TRUE)
# Reemplazar ceros con la mediana
data[[col]][data[[col]] == 0] <- mediana
}
return(data)
}
# Especificar las columnas a procesar
columnas_a_procesar <- c("Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI")
# Aplicar la función al dataset
diabetes_data <- reemplazar_con_mediana(diabetes_data, columnas_a_procesar)
# Verificar resultados
summary(diabetes_data)
# Análisis exploratorio
ggplot(diabetes_data, aes(x = Glucose)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Glucosa", x = "Glucosa", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Pregnancies)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Embarazos", x = "Embarazos", y = "Frecuencia")
ggplot(diabetes_data, aes(x = BloodPressure)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Presión Arterial", x = "Presión Arterial", y = "Frecuencia")
ggplot(diabetes_data, aes(x = SkinThickness)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Grosor de Piel", x = "Grosor de Piel", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Insulin)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Insulina", x = "Insulina", y = "Frecuencia")
ggplot(diabetes_data, aes(x = BMI)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de IMC", x = "IMC", y = "Frecuencia")
ggplot(diabetes_data, aes(x = DiabetesPedigreeFunction)) +
geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Distribución de la Función de Pedigrí de Diabetes", x = "Diabetes Pedigree Function", y = "Frecuencia") +
theme_minimal()
ggplot(diabetes_data, aes(x = Age)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribución de Edad", x = "Edad", y = "Frecuencia")
ggplot(diabetes_data, aes(x = Outcome)) +
geom_bar(fill = "salmon", color = "black") +
labs(title = "Distribución de Outcome", x = "Resultado de Diabetes", y = "Frecuencia")
# Estadísticas descriptivas de las variables
summary(diabetes_data)
# Selección de columnas numéricas
variables_numericas <- diabetes_data[sapply(diabetes_data, is.numeric)]
# Calcular la matriz de correlación
matriz_correlacion <- cor(variables_numericas, use = "complete.obs")
# Ver la matriz de correlación
print(matriz_correlacion)
# Graficar matriz de correlacion
correlacion_larga <- melt(matriz_correlacion)
ggplot(data = correlacion_larga, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1, 1), name = "Correlación") +
theme_minimal() +
labs(title = "Matriz de Correlación", x = "", y = "") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Dividir los datos en conjunto de entrenamiento y prueba
set.seed(42) # Para reproducibilidad
indices <- createDataPartition(diabetes_data$Outcome, p = 0.7, list = FALSE)
train_data <- diabetes_data[indices, ] # EXPLICAR POR QUÉ SE ESCOGIÓ EL 70% DE LOS DATOS PARA EL ENTRENAMIENTO
test_data <- diabetes_data[-indices, ]
# Falsos positivos y negativos
false_positive <- which(predicciones == 1 & test_data$Outcome == 0)
false_negative <- which(predicciones == 0 & test_data$Outcome == 1)
# Mostrar los ejemplos mal clasificados
print(test_data[false_positive, ])
print(test_data[false_negative, ])
# Proporción de clases en el conjunto de entrenamiento y prueba
table(train_data$Outcome)
table(test_data$Outcome)
test_data <- diabetes_data[-indices, ]
# Proporción de clases en el conjunto de entrenamiento y prueba
table(train_data$Outcome)
table(test_data$Outcome)
# Grid search de hiperparámetros con métricas adicionales
mejores_resultados <- NULL
valores_cf <- c(0.05, 0.1, 0.15, 0.25)
valores_minCases <- c(5, 10, 15)
valores_trials <- c(5, 10, 20)
for (cf in valores_cf) {
for (min_cases in valores_minCases) {
for (trials in valores_trials) {
# Entrenar el modelo con la combinación actual
modelo <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = cf, minCases = min_cases),
trials = trials)
# Evaluar en el conjunto de prueba
predicciones <- predict(modelo, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
# Calcular métricas adicionales
accuracy <- matriz_confusion$overall['Accuracy']
sensitivity <- matriz_confusion$byClass['Sensitivity']
specificity <- matriz_confusion$byClass['Specificity']
precision <- matriz_confusion$byClass['Pos Pred Value']
f1_score <- (2 * precision * sensitivity) / (precision + sensitivity)
# Guardar los resultados
mejores_resultados <- rbind(
mejores_resultados,
data.frame(
CF = cf,
minCases = min_cases,
Trials = trials,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
Precision = precision,
F1_Score = f1_score
)
)
}
}
}
# Ordenar los resultados por la métrica deseada (ej., F1_Score o Accuracy)
mejores_resultados <- mejores_resultados[order(-mejores_resultados$Accuracy, -mejores_resultados$F1_Score), ]
# Mostrar las mejores combinaciones
print(mejores_resultados)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
# Gráfico del mejor modelo
plot(modelo_c50)
# Resumen del mejor modelo
summary(modelo_c50)
# Predicciones con datos de pruebas
predicciones <- predict(modelo, test_data)
# Predicciones con datos de pruebas
predicciones <- predict(modelo_c50, test_data)
matriz_confusion <- confusionMatrix(predicciones, test_data$Outcome)
# Matriz de confusión
print(matriz_confusion)
# Crear gráfico de importancia de las variables
importancia <- C5imp(modelo_c50)
importance_df <- data.frame(Variable = rownames(importancia), Importancia = importancia[, 1])
# Crear gráfico de importancia de las variables
importancia <- C5imp(modelo_c50)
importance_df <- data.frame(Variable = rownames(importancia), Importancia = importancia[, 1])
ggplot(importance_df, aes(x = reorder(Variable, Importancia), y = Importancia)) +
geom_bar(stat = "identity", fill = "darkblue", color = "black") +
coord_flip() +
labs(title = "Importancia de las variables", x = "Variable", y = "Importancia")
# Validación cruzada
set.seed(42)
train_control <- trainControl(method = "cv", number = 10) # 10-fold cross-validation
# Entrenamiento del modelo con validación cruzada
modelo_cv <- train(Outcome ~ ., data = train_data,
method = "C5.0",
trControl = train_control,
tuneGrid = expand.grid(trials = c(5, 10, 20),
model = "tree",
winnow = FALSE))
# Resultados de validación cruzada
print(modelo_cv)
plot(modelo_cv)
# Resultados de validación cruzada
print(modelo_cv)
# Calcular la probabilidad de predicción
probabilidades <- predict(modelo_c50, test_data, type = "prob")
# Crear la curva ROC
roc_curve <- roc(test_data$Outcome, probabilidades[, 2], levels = rev(levels(test_data$Outcome)))
plot(roc_curve, col = "blue", lwd = 2, main = "Curva ROC del Modelo C5.0")
library(pROC)
# Calcular la probabilidad de predicción
probabilidades <- predict(modelo_c50, test_data, type = "prob")
# Crear la curva ROC
roc_curve <- roc(test_data$Outcome, probabilidades[, 2], levels = rev(levels(test_data$Outcome)))
plot(roc_curve, col = "blue", lwd = 2, main = "Curva ROC del Modelo C5.0")
auc_value <- auc(roc_curve)
print(paste("Área Bajo la Curva (AUC):", round(auc_value, 4)))
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
# Gráfico del mejor modelo
plot(modelo_c50)
# Resumen del mejor modelo
summary(modelo_c50)
print(modelo_c50)
# Resumen del mejor modelo
summary(modelo_c50)
print(modelo_c50$rules)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
# Gráfico del mejor modelo
plot(modelo_c50)
print(modelo_c50$rules)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5, rules = TRUE)
# Gráfico del mejor modelo
plot(modelo_c50)
modelo_c50 <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5)
modelo <- C5.0(Outcome ~ ., data = train_data,
control = C5.0Control(CF = 0.10, minCases = 15),
trials = 5, rules = TRUE)
print(modelo$rules)
