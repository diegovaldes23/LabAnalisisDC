pam_fit <- pam(scaled_data, k = k)
return(sum(pam_fit$clustering))
}
# Valores de k a probar
k_values <- 1:10
# Calcular la inercia para cada valor de k
wss_values <- map_dbl(k_values, wss)
# Graficar el método del codo
plot(k_values, wss_values,
type = "b", pch = 19, frame = FALSE,
xlab = "Número de Clusters K",
ylab = "Inercia intra-cluster")
# ------------------------------------
# Método 2: Índice de la Silueta
# ------------------------------------
silhouette_score <- function(k) {
pam_fit <- pam(scaled_data, k = k)
silhouette <- silhouette(pam_fit$clustering, dist(scaled_data))
return(mean(silhouette[, 3]))  # Retorna el promedio del índice de silueta
}
# Calcular el índice de silueta para cada valor de k
sil_values <- map_dbl(k_values, silhouette_score)
# Graficar el índice de la silueta
plot(k_values, sil_values,
type = "b", pch = 19, frame = FALSE,
xlab = "Número de Clusters K",
ylab = "Índice de la Silueta")
# ------------------------------------
# Método 3: Gap Statistic (Criterio de la Brecha)
# ------------------------------------
gap_stat <- clusGap(scaled_data, FUN = pam, K.max = 10, B = 50)
# Graficar los resultados del Gap Statistic
fviz_gap_stat(gap_stat)
# ------------------------------------
# Definir el número de clusters (puedes ajustar según los análisis previos)
num_clusters <- 3  # Cambia este valor según los resultados obtenidos de los métodos anteriores
# Aplicar K-Medoids utilizando la función 'pam'
pam_fit <- pam(scaled_data, k = num_clusters)
# Parte 4: Visualización de los clusters
fviz_cluster(pam_fit, geom = "point", ellipse.type = "norm")
# Mostrar los resultados del clustering
print(pam_fit)
# Cargar los paquetes necesarios
library(cluster)
library(factoextra)
library(purrr)
# Parte 1: Cargar los datos
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Parte 2: Limpieza de datos
# Reemplazar los ceros por NA en las columnas donde no tiene sentido que haya ceros
diabetes_data$Glucose[diabetes_data$Glucose == 0] <- NA
diabetes_data$BloodPressure[diabetes_data$BloodPressure == 0] <- NA
diabetes_data$SkinThickness[diabetes_data$SkinThickness == 0] <- NA
diabetes_data$Insulin[diabetes_data$Insulin == 0] <- NA
diabetes_data$BMI[diabetes_data$BMI == 0] <- NA
diabetes_data$DiabetesPedigreeFunction[diabetes_data$DiabetesPedigreeFunction == 0] <- NA
# Imputar los valores faltantes con la media
diabetes_data$Glucose[is.na(diabetes_data$Glucose)] <- mean(diabetes_data$Glucose, na.rm = TRUE)
diabetes_data$BloodPressure[is.na(diabetes_data$BloodPressure)] <- mean(diabetes_data$BloodPressure, na.rm = TRUE)
diabetes_data$SkinThickness[is.na(diabetes_data$SkinThickness)] <- mean(diabetes_data$SkinThickness, na.rm = TRUE)
diabetes_data$Insulin[is.na(diabetes_data$Insulin)] <- mean(diabetes_data$Insulin, na.rm = TRUE)
diabetes_data$BMI[is.na(diabetes_data$BMI)] <- mean(diabetes_data$BMI, na.rm = TRUE)
diabetes_data$DiabetesPedigreeFunction[is.na(diabetes_data$DiabetesPedigreeFunction)] <- mean(diabetes_data$DiabetesPedigreeFunction, na.rm = TRUE)
# Mostrar estructura de los datos
str(diabetes_data)
# Resumen estadístico básico de todas las variables
summary(diabetes_data)
# Parte 3: Clustering con K-Medoids
# Escalar los datos antes de aplicar el algoritmo
scaled_data <- scale(diabetes_data)
# ------------------------------------
# Método 1: Elbow Method (Método del Codo)
# ------------------------------------
wss <- function(k) {
pam_fit <- pam(scaled_data, k = k)
return(sum(pam_fit$clustering))
}
# Valores de k a probar
k_values <- 1:10
# Calcular la inercia para cada valor de k
wss_values <- map_dbl(k_values, wss)
# Graficar el método del codo
plot(k_values, wss_values,
type = "b", pch = 19, frame = FALSE,
xlab = "Número de Clusters K",
ylab = "Inercia intra-cluster")
# ------------------------------------
# Método 2: Índice de la Silueta
silhouette_score <- function(k) {
if (k == 1) {
return(NA)  # No se puede calcular el índice de silueta con un solo cluster
}
pam_fit <- pam(scaled_data, k = k)
silhouette <- silhouette(pam_fit$clustering, dist(scaled_data))
return(mean(silhouette[, 3]))  # Retorna el promedio del índice de silueta
}
# Calcular el índice de silueta para cada valor de k
sil_values <- map_dbl(k_values, silhouette_score)
# Eliminar valores NA para la visualización
k_values_valid <- k_values[!is.na(sil_values)]
sil_values_valid <- sil_values[!is.na(sil_values)]
# Graficar el índice de la silueta
plot(k_values_valid, sil_values_valid,
type = "b", pch = 19, frame = FALSE,
xlab = "Número de Clusters K",
ylab = "Índice de la Silueta")
# ------------------------------------
# Método 3: Gap Statistic (Criterio de la Brecha)
# ------------------------------------
gap_stat <- clusGap(scaled_data, FUN = pam, K.max = 10, B = 50)
# Graficar los resultados del Gap Statistic
fviz_gap_stat(gap_stat)
# ------------------------------------
# Definir el número de clusters (puedes ajustar según los análisis previos)
num_clusters <- 3  # Cambia este valor según los resultados obtenidos de los métodos anteriores
# Aplicar K-Medoids utilizando la función 'pam'
pam_fit <- pam(scaled_data, k = num_clusters)
# Parte 4: Visualización de los clusters
fviz_cluster(pam_fit, geom = "point", ellipse.type = "norm")
# Mostrar los resultados del clustering
print(pam_fit)
# Cargar los paquetes necesarios
library(cluster)
library(factoextra)
library(purrr)
# Parte 1: Cargar los datos
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Parte 2: Limpieza de datos
# Reemplazar los ceros por NA en las columnas donde no tiene sentido que haya ceros
diabetes_data$Glucose[diabetes_data$Glucose == 0] <- NA
diabetes_data$BloodPressure[diabetes_data$BloodPressure == 0] <- NA
diabetes_data$SkinThickness[diabetes_data$SkinThickness == 0] <- NA
diabetes_data$Insulin[diabetes_data$Insulin == 0] <- NA
diabetes_data$BMI[diabetes_data$BMI == 0] <- NA
diabetes_data$DiabetesPedigreeFunction[diabetes_data$DiabetesPedigreeFunction == 0] <- NA
# Parte 3: Imputación de valores faltantes
# Imputar los valores NA con la media de cada columna
diabetes_data$Glucose[is.na(diabetes_data$Glucose)] <- mean(diabetes_data$Glucose, na.rm = TRUE)
diabetes_data$BloodPressure[is.na(diabetes_data$BloodPressure)] <- mean(diabetes_data$BloodPressure, na.rm = TRUE)
diabetes_data$SkinThickness[is.na(diabetes_data$SkinThickness)] <- mean(diabetes_data$SkinThickness, na.rm = TRUE)
diabetes_data$Insulin[is.na(diabetes_data$Insulin)] <- mean(diabetes_data$Insulin, na.rm = TRUE)
diabetes_data$BMI[is.na(diabetes_data$BMI)] <- mean(diabetes_data$BMI, na.rm = TRUE)
diabetes_data$DiabetesPedigreeFunction[is.na(diabetes_data$DiabetesPedigreeFunction)] <- mean(diabetes_data$DiabetesPedigreeFunction, na.rm = TRUE)
# Mostrar estructura de los datos
str(diabetes_data)
# Resumen estadístico básico de todas las variables
summary(diabetes_data)
# Parte 4: Normalización de los datos
# Normalizar los datos numéricos (todas las variables numéricas tendrán media = 0 y desviación estándar = 1)
diabetes_data_scaled <- scale(diabetes_data)
# Verificar los datos normalizados
head(diabetes_data_scaled)
# Parte : Clustering con K-Medoids
# Escalar los datos antes de aplicar el algoritmo
scaled_data <- scale(diabetes_data)
# ------------------------------------
# Método 1: Elbow Method (Método del Codo)
# ------------------------------------
wss <- function(k) {
pam_fit <- pam(scaled_data, k = k)
return(sum(pam_fit$clustering))
}
# Cargar los paquetes necesarios
library(cluster)
library(factoextra)
library(purrr)
# Parte 1: Cargar los datos
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Parte 2: Limpieza de datos
# Reemplazar los ceros por NA en las columnas donde no tiene sentido que haya ceros
diabetes_data$Glucose[diabetes_data$Glucose == 0] <- NA
diabetes_data$BloodPressure[diabetes_data$BloodPressure == 0] <- NA
diabetes_data$SkinThickness[diabetes_data$SkinThickness == 0] <- NA
diabetes_data$Insulin[diabetes_data$Insulin == 0] <- NA
diabetes_data$BMI[diabetes_data$BMI == 0] <- NA
diabetes_data$DiabetesPedigreeFunction[diabetes_data$DiabetesPedigreeFunction == 0] <- NA
# Parte 3: Imputación de valores faltantes
# Imputar los valores NA con la media de cada columna
diabetes_data$Glucose[is.na(diabetes_data$Glucose)] <- mean(diabetes_data$Glucose, na.rm = TRUE)
diabetes_data$BloodPressure[is.na(diabetes_data$BloodPressure)] <- mean(diabetes_data$BloodPressure, na.rm = TRUE)
diabetes_data$SkinThickness[is.na(diabetes_data$SkinThickness)] <- mean(diabetes_data$SkinThickness, na.rm = TRUE)
diabetes_data$Insulin[is.na(diabetes_data$Insulin)] <- mean(diabetes_data$Insulin, na.rm = TRUE)
diabetes_data$BMI[is.na(diabetes_data$BMI)] <- mean(diabetes_data$BMI, na.rm = TRUE)
diabetes_data$DiabetesPedigreeFunction[is.na(diabetes_data$DiabetesPedigreeFunction)] <- mean(diabetes_data$DiabetesPedigreeFunction, na.rm = TRUE)
# Mostrar estructura de los datos
str(diabetes_data)
# Resumen estadístico básico de todas las variables
summary(diabetes_data)
# Parte 4: Normalización de los datos
# Normalizar los datos numéricos (todas las variables numéricas tendrán media = 0 y desviación estándar = 1)
diabetes_data_scaled <- scale(diabetes_data)
# Verificar los datos normalizados
head(diabetes_data_scaled)
# Cargar los paquetes necesarios
library(cluster)
library(factoextra)
library(purrr)
# Parte 1: Cargar los datos
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar los paquetes necesarios
library(cluster)
library(factoextra)
library(purrr)
# Parte 1: Cargar los datos
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Parte 2: Limpieza de datos
# Reemplazar los ceros por NA en las columnas donde no tiene sentido que haya ceros
diabetes_data$Glucose[diabetes_data$Glucose == 0] <- NA
diabetes_data$BloodPressure[diabetes_data$BloodPressure == 0] <- NA
diabetes_data$SkinThickness[diabetes_data$SkinThickness == 0] <- NA
diabetes_data$Insulin[diabetes_data$Insulin == 0] <- NA
diabetes_data$BMI[diabetes_data$BMI == 0] <- NA
diabetes_data$DiabetesPedigreeFunction[diabetes_data$DiabetesPedigreeFunction == 0] <- NA
# Parte 3: Imputación de valores faltantes
# Imputar los valores NA con la media de cada columna
diabetes_data$Glucose[is.na(diabetes_data$Glucose)] <- mean(diabetes_data$Glucose, na.rm = TRUE)
diabetes_data$BloodPressure[is.na(diabetes_data$BloodPressure)] <- mean(diabetes_data$BloodPressure, na.rm = TRUE)
diabetes_data$SkinThickness[is.na(diabetes_data$SkinThickness)] <- mean(diabetes_data$SkinThickness, na.rm = TRUE)
diabetes_data$Insulin[is.na(diabetes_data$Insulin)] <- mean(diabetes_data$Insulin, na.rm = TRUE)
diabetes_data$BMI[is.na(diabetes_data$BMI)] <- mean(diabetes_data$BMI, na.rm = TRUE)
diabetes_data$DiabetesPedigreeFunction[is.na(diabetes_data$DiabetesPedigreeFunction)] <- mean(diabetes_data$DiabetesPedigreeFunction, na.rm = TRUE)
# Mostrar estructura de los datos
str(diabetes_data)
# Resumen estadístico básico de todas las variables
summary(diabetes_data)
# Parte 4: Normalización de los datos
# Normalizar los datos numéricos (todas las variables numéricas tendrán media = 0 y desviación estándar = 1)
diabetes_data_scaled <- scale(diabetes_data)
# Verificar los datos normalizados
head(diabetes_data_scaled)
# ------------------------------------
# Método 1: Elbow Method (Método del Codo)
# ------------------------------------
wss <- function(k) {
pam_fit <- pam(diabetes_data_scaled, k = k)
return(sum(pam_fit$objective))  # Usa la suma de distancias intra-cluster
}
# Valores de k a probar
k_values <- 1:10
# Calcular la inercia para cada valor de k
wss_values <- map_dbl(k_values, wss)
# Graficar el método del codo
plot(k_values, wss_values,
type = "b", pch = 19, frame = FALSE,
xlab = "Número de Clusters K",
ylab = "Inercia intra-cluster")
# ------------------------------------
# Método 2: Índice de la Silueta
silhouette_score <- function(k) {
if (k == 1) {
return(NA)  # No se puede calcular el índice de silueta con un solo cluster
}
pam_fit <- pam(diabetes_data_scaled, k = k)
silhouette <- silhouette(pam_fit$clustering, dist(diabetes_data_scaled))
return(mean(silhouette[, 3]))  # Retorna el promedio del índice de silueta
}
# Calcular el índice de silueta para cada valor de k
sil_values <- map_dbl(k_values, silhouette_score)
# Eliminar valores NA para la visualización
k_values_valid <- k_values[!is.na(sil_values)]
sil_values_valid <- sil_values[!is.na(sil_values)]
# Graficar el índice de la silueta
plot(k_values_valid, sil_values_valid,
type = "b", pch = 19, frame = FALSE,
xlab = "Número de Clusters K",
ylab = "Índice de la Silueta")
# ------------------------------------
# Método 3: Gap Statistic (Criterio de la Brecha)
# ------------------------------------
gap_stat <- clusGap(diabetes_data_scaled, FUN = pam, K.max = 10, B = 50)
# Graficar los resultados del Gap Statistic
fviz_gap_stat(gap_stat)
# Graficar los resultados del Gap Statistic
fviz_gap_stat(gap_stat)
# ------------------------------------
# Definir el número de clusters (puedes ajustar según los análisis previos)
num_clusters <- 3  # Cambia este valor según los resultados obtenidos de los métodos anteriores
# Aplicar K-Medoids utilizando la función 'pam'
pam_fit <- pam(diabetes_data_scaled, k = num_clusters)
# Parte 4: Visualización de los clusters
fviz_cluster(pam_fit, geom = "point", ellipse.type = "norm")
# Mostrar los resultados del clustering
print(pam_fit)
# Cargar los paquetes necesarios
library(cluster)
library(factoextra)
library(purrr)
# Parte 1: Cargar los datos
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Parte 2: Limpieza de datos
# Reemplazar los ceros por NA en las columnas donde no tiene sentido que haya ceros
diabetes_data$Glucose[diabetes_data$Glucose == 0] <- NA
diabetes_data$BloodPressure[diabetes_data$BloodPressure == 0] <- NA
diabetes_data$SkinThickness[diabetes_data$SkinThickness == 0] <- NA
diabetes_data$Insulin[diabetes_data$Insulin == 0] <- NA
diabetes_data$BMI[diabetes_data$BMI == 0] <- NA
diabetes_data$DiabetesPedigreeFunction[diabetes_data$DiabetesPedigreeFunction == 0] <- NA
# Parte 3: Imputación de valores faltantes
# Imputar los valores NA con la media de cada columna
diabetes_data$Glucose[is.na(diabetes_data$Glucose)] <- mean(diabetes_data$Glucose, na.rm = TRUE)
diabetes_data$BloodPressure[is.na(diabetes_data$BloodPressure)] <- mean(diabetes_data$BloodPressure, na.rm = TRUE)
diabetes_data$SkinThickness[is.na(diabetes_data$SkinThickness)] <- mean(diabetes_data$SkinThickness, na.rm = TRUE)
diabetes_data$Insulin[is.na(diabetes_data$Insulin)] <- mean(diabetes_data$Insulin, na.rm = TRUE)
diabetes_data$BMI[is.na(diabetes_data$BMI)] <- mean(diabetes_data$BMI, na.rm = TRUE)
diabetes_data$DiabetesPedigreeFunction[is.na(diabetes_data$DiabetesPedigreeFunction)] <- mean(diabetes_data$DiabetesPedigreeFunction, na.rm = TRUE)
# Mostrar estructura de los datos
str(diabetes_data)
# Resumen estadístico básico de todas las variables
summary(diabetes_data)
# Parte 4: Normalización de los datos
# Normalizar los datos numéricos (todas las variables numéricas tendrán media = 0 y desviación estándar = 1)
diabetes_data_scaled <- scale(diabetes_data)
# Verificar los datos normalizados
head(diabetes_data_scaled)
# ------------------------------------
# Método 1: Elbow Method (Método del Codo)
# ------------------------------------
wss <- function(k) {
pam_fit <- pam(diabetes_data_scaled, k = k)
return(sum(pam_fit$objective))  # Usa la suma de distancias intra-cluster
}
# Valores de k a probar
k_values <- 1:10
# Calcular la inercia para cada valor de k
wss_values <- map_dbl(k_values, wss)
# Graficar el método del codo
plot(k_values, wss_values,
type = "b", pch = 19, frame = FALSE,
xlab = "Número de Clusters K",
ylab = "Inercia intra-cluster")
# ------------------------------------
# Método 2: Índice de la Silueta
silhouette_score <- function(k) {
if (k == 1) {
return(NA)  # No se puede calcular el índice de silueta con un solo cluster
}
pam_fit <- pam(diabetes_data_scaled, k = k)
silhouette <- silhouette(pam_fit$clustering, dist(diabetes_data_scaled))
return(mean(silhouette[, 3]))  # Retorna el promedio del índice de silueta
}
# Calcular el índice de silueta para cada valor de k
sil_values <- map_dbl(k_values, silhouette_score)
# Eliminar valores NA para la visualización
k_values_valid <- k_values[!is.na(sil_values)]
sil_values_valid <- sil_values[!is.na(sil_values)]
# Graficar el índice de la silueta
plot(k_values_valid, sil_values_valid,
type = "b", pch = 19, frame = FALSE,
xlab = "Número de Clusters K",
ylab = "Índice de la Silueta")
# ------------------------------------
# Método 3: Gap Statistic (Criterio de la Brecha)
# ------------------------------------
gap_stat <- clusGap(diabetes_data_scaled, FUN = pam, K.max = 10, B = 50)
# Graficar los resultados del Gap Statistic
fviz_gap_stat(gap_stat)
# ------------------------------------
# Definir el número de clusters (puedes ajustar según los análisis previos)
num_clusters <- 4 # Cambia este valor según los resultados obtenidos de los métodos anteriores
# Aplicar K-Medoids utilizando la función 'pam'
pam_fit <- pam(diabetes_data_scaled, k = num_clusters)
# Parte 4: Visualización de los clusters
fviz_cluster(pam_fit, geom = "point", ellipse.type = "norm")
# Mostrar los resultados del clustering
print(pam_fit)
# ------------------------------------
# Definir el número de clusters (puedes ajustar según los análisis previos)
num_clusters <- 5# Cambia este valor según los resultados obtenidos de los métodos anteriores
# Aplicar K-Medoids utilizando la función 'pam'
pam_fit <- pam(diabetes_data_scaled, k = num_clusters)
# Parte 4: Visualización de los clusters
fviz_cluster(pam_fit, geom = "point", ellipse.type = "norm")
# Mostrar los resultados del clustering
print(pam_fit)
# ------------------------------------
# Definir el número de clusters (puedes ajustar según los análisis previos)
num_clusters <- 3  # Cambia este valor según los resultados obtenidos de los métodos anteriores
# Aplicar K-Medoids utilizando la función 'pam'
pam_fit <- pam(diabetes_data_scaled, k = num_clusters)
# Parte 4: Visualización de los clusters
fviz_cluster(pam_fit, geom = "point", ellipse.type = "norm")
# Mostrar los resultados del clustering
print(pam_fit)
# ------------------------------------
# Definir el número de clusters (puedes ajustar según los análisis previos)
num_clusters <- 4# Cambia este valor según los resultados obtenidos de los métodos anteriores
# Aplicar K-Medoids utilizando la función 'pam'
pam_fit <- pam(diabetes_data_scaled, k = num_clusters)
# Parte 4: Visualización de los clusters
fviz_cluster(pam_fit, geom = "point", ellipse.type = "norm")
# Mostrar los resultados del clustering
print(pam_fit)
# Cargar los paquetes necesarios
library(cluster)
library(factoextra)
library(purrr)
# Parte 1: Cargar los datos
# Obtener la ruta del directorio de trabajo actual
current_dir <- getwd()
# Buscar el archivo "diabetes.csv" en el directorio actual y subdirectorios
file_name <- "diabetes.csv"
file_path <- list.files(path = current_dir, pattern = file_name, recursive = TRUE, full.names = TRUE)
# Cargar el archivo si existe
if (length(file_path) > 0) {
diabetes_data <- read.csv(file_path[1])
print("Archivo cargado correctamente.")
} else {
print("El archivo no fue encontrado.")
}
# Mostrar las primeras filas del conjunto de datos
head(diabetes_data)
# Parte 2: Limpieza de datos
# Reemplazar los ceros por NA en las columnas donde no tiene sentido que haya ceros
diabetes_data$Glucose[diabetes_data$Glucose == 0] <- NA
diabetes_data$BloodPressure[diabetes_data$BloodPressure == 0] <- NA
diabetes_data$SkinThickness[diabetes_data$SkinThickness == 0] <- NA
diabetes_data$Insulin[diabetes_data$Insulin == 0] <- NA
diabetes_data$BMI[diabetes_data$BMI == 0] <- NA
diabetes_data$DiabetesPedigreeFunction[diabetes_data$DiabetesPedigreeFunction == 0] <- NA
# Parte 3: Imputación de valores faltantes
# Imputar los valores NA con la media de cada columna
diabetes_data$Glucose[is.na(diabetes_data$Glucose)] <- mean(diabetes_data$Glucose, na.rm = TRUE)
diabetes_data$BloodPressure[is.na(diabetes_data$BloodPressure)] <- mean(diabetes_data$BloodPressure, na.rm = TRUE)
diabetes_data$SkinThickness[is.na(diabetes_data$SkinThickness)] <- mean(diabetes_data$SkinThickness, na.rm = TRUE)
diabetes_data$Insulin[is.na(diabetes_data$Insulin)] <- mean(diabetes_data$Insulin, na.rm = TRUE)
diabetes_data$BMI[is.na(diabetes_data$BMI)] <- mean(diabetes_data$BMI, na.rm = TRUE)
diabetes_data$DiabetesPedigreeFunction[is.na(diabetes_data$DiabetesPedigreeFunction)] <- mean(diabetes_data$DiabetesPedigreeFunction, na.rm = TRUE)
# Mostrar estructura de los datos
str(diabetes_data)
# Resumen estadístico básico de todas las variables
summary(diabetes_data)
# Parte 4: Normalización de los datos
# Normalizar los datos numéricos (todas las variables numéricas tendrán media = 0 y desviación estándar = 1)
diabetes_data_scaled <- scale(diabetes_data)
# Verificar los datos normalizados
head(diabetes_data_scaled)
# ------------------------------------
# Método 1: Elbow Method (Método del Codo)
# ------------------------------------
wss <- function(k) {
pam_fit <- pam(diabetes_data_scaled, k = k)
return(sum(pam_fit$objective))  # Usa la suma de distancias intra-cluster
}
